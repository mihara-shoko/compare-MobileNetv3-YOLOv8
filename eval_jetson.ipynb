{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c4c1928",
   "metadata": {},
   "source": [
    "# plan (engine) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3a5ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c66ba06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load engine file\n",
    "\n",
    "import tensorrt as trt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "\n",
    "class HostDeviceMem(object):\n",
    "    def __init__(self, host_mem, device_mem):\n",
    "        self.host = host_mem\n",
    "        self.device = device_mem\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Host:\\n\" + str(self.host) + \"\\nDevice:\\n\" + str(self.device)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "class TrtModel:\n",
    "    \n",
    "    def __init__(self,engine_path,max_batch_size=1,dtype=np.float32):\n",
    "        \n",
    "        self.engine_path = engine_path\n",
    "        self.dtype = dtype\n",
    "        self.logger = trt.Logger(trt.Logger.WARNING)\n",
    "        self.runtime = trt.Runtime(self.logger)\n",
    "        self.engine = self.load_engine(self.runtime, self.engine_path)\n",
    "        self.max_batch_size = max_batch_size\n",
    "        self.inputs, self.outputs, self.bindings, self.stream = self.allocate_buffers()\n",
    "        self.context = self.engine.create_execution_context()\n",
    "\n",
    "                \n",
    "                \n",
    "    @staticmethod\n",
    "    def load_engine(trt_runtime, engine_path):\n",
    "        trt.init_libnvinfer_plugins(None, \"\")             \n",
    "        with open(engine_path, 'rb') as f:\n",
    "            engine_data = f.read()\n",
    "        engine = trt_runtime.deserialize_cuda_engine(engine_data)\n",
    "        return engine\n",
    "    \n",
    "    def allocate_buffers(self):\n",
    "        \n",
    "        inputs = []\n",
    "        outputs = []\n",
    "        bindings = []\n",
    "        stream = cuda.Stream()\n",
    "        \n",
    "        for binding in self.engine:\n",
    "            size = trt.volume(self.engine.get_binding_shape(binding)) * self.max_batch_size\n",
    "            host_mem = cuda.pagelocked_empty(size, self.dtype)\n",
    "            device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "            \n",
    "            bindings.append(int(device_mem))\n",
    "\n",
    "            if self.engine.binding_is_input(binding):\n",
    "                inputs.append(HostDeviceMem(host_mem, device_mem))\n",
    "            else:\n",
    "                outputs.append(HostDeviceMem(host_mem, device_mem))\n",
    "        \n",
    "        return inputs, outputs, bindings, stream\n",
    "       \n",
    "            \n",
    "    def __call__(self,x:np.ndarray,batch_size=1):\n",
    "        \n",
    "        x = x.astype(self.dtype)\n",
    "        \n",
    "        np.copyto(self.inputs[0].host,x.ravel())\n",
    "        \n",
    "        for inp in self.inputs:\n",
    "            cuda.memcpy_htod_async(inp.device, inp.host, self.stream)\n",
    "        \n",
    "        self.context.execute_async(batch_size=batch_size, bindings=self.bindings, stream_handle=self.stream.handle)\n",
    "        for out in self.outputs:\n",
    "            cuda.memcpy_dtoh_async(out.host, out.device, self.stream) \n",
    "            \n",
    "        \n",
    "        self.stream.synchronize()\n",
    "        return [out.host.reshape(batch_size,-1) for out in self.outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e72baad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_yolo(img_file):\n",
    "    img_size = 224\n",
    "    stride = 32\n",
    "\n",
    "    img = cv2.imread(img_file)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    imh, imw = img.shape[:2]\n",
    "    r = min(img_size / imh, img_size / imw)\n",
    "    h, w = round(imh * r), round(imw * r)\n",
    "    # hs, ws = (math.ceil(x / stride) * stride for x in (h, w))\n",
    "    hs, ws = 224, 224\n",
    "    top, left = round((hs - h) / 2 - 0.1), round((ws - w) / 2 - 0.1)\n",
    "    img_pad = np.full((img_size, img_size, 3), 114, dtype=img.dtype)\n",
    "    img_pad[top:top + h, left:left + w] = cv2.resize(img, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "\n",
    "    img_norm = img_pad/255\n",
    "\n",
    "    face = np.empty((1, img_size, img_size, 3))\n",
    "    face[0,:,:,:] = img_norm\n",
    "    face = np.transpose(face, (0, 3, 1, 2))\n",
    "\n",
    "    return face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07c09504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_yolo(img_files, model):\n",
    "\n",
    "    pred_list = []\n",
    "    gt_list = []\n",
    "\n",
    "    for img_file in img_files:\n",
    "        img = get_img_yolo(img_file)\n",
    "        pred = model(img)\n",
    "        class_id = np.argmax(pred)\n",
    "\n",
    "        if class_id == 0:\n",
    "            pred_gender = \"female\"\n",
    "        else:\n",
    "            pred_gender = \"male\"\n",
    "\n",
    "        if int(os.path.basename(img_file).split(\"A\")[0]) <= 7380:\n",
    "            gt_gender = \"female\"\n",
    "        else:\n",
    "            gt_gender = \"male\"\n",
    "\n",
    "        pred_list.append(pred_gender)\n",
    "        gt_list.append(gt_gender)\n",
    "\n",
    "    return gt_list, pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22df9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accuracy(gt, pred):\n",
    "    accuracy = accuracy_score(gt, pred)\n",
    "    print(\"accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29009c3a",
   "metadata": {},
   "source": [
    "# YOLOv8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae142e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(287, 287)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_files_female = glob(\"test/female/*\")\n",
    "img_files_male = glob(\"test/male/*\")\n",
    "len(img_files_female), len(img_files_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2284caf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 224, 224)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load engine model\n",
    "batch_size = 1 \n",
    "trt_engine_path = 'yolov8s_cls_gender.plan'\n",
    "model = TrtModel(trt_engine_path)\n",
    "shape = model.engine.get_binding_shape(0)\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c53cc700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female\n",
      "accuracy:  0.9337979094076655\n",
      "male\n",
      "accuracy:  0.9024390243902439\n",
      "all\n",
      "accuracy:  0.9181184668989547\n"
     ]
    }
   ],
   "source": [
    "# inference\n",
    "# female\n",
    "print(\"female\")\n",
    "gt_female, pred_female = prediction_yolo(img_files_female, model)\n",
    "cal_accuracy(gt_female, pred_female)\n",
    "# male\n",
    "print(\"male\")\n",
    "gt_male, pred_male = prediction_yolo(img_files_male, model)\n",
    "cal_accuracy(gt_male, pred_male)\n",
    "# all\n",
    "print(\"all\")\n",
    "gt_female.extend(gt_male)\n",
    "pred_female.extend(pred_male)\n",
    "cal_accuracy(gt_female, pred_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b869a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d380d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905530d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
